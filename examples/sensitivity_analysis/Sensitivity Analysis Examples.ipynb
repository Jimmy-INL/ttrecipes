{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT recipes: Sensitivity Analysis Examples\n",
    "\n",
    "This notebook shows how to use the __sensibility analysis__ methods from __TT tecipes__. These examples use functions from the built-in library of well-known test functions included in the submodule _models_. Some of these examples have been used for related scientific publications:\n",
    "\n",
    "  - [1] _Sobol Tensor Trains for Global Sensitivity Analysis._\n",
    "    Rafael Ballester-Ripoll, Enrique G. Paredes, Renato Pajarola\n",
    "    [[arXiv](https://arxiv.org/abs/1712.00233)]\n",
    "\n",
    "  - [2] _Tensor Approximation of Advanced Metrics for Sensitivity Analysis._\n",
    "    Rafael Ballester-Ripoll, Enrique G. Paredes, Renato Pajarola\n",
    "    [[arXiv]()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# The most important \"import\" statement!\n",
    "import ttrecipes as tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set some general settings for the examples in this tutorial:\n",
    "\n",
    "  - __bins__ will be used as the default number of samples per axis\n",
    "  - __max_order__ indicates the maximum order of the indices reported (all possible orders are always computed, this only affects the report tables)\n",
    "  - __verbose__ sets the _verbose_ mode to __True__ or __False__\n",
    "  - __seed__ is the random seed that will be used for Python and NumPy's random generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of samples per axis\n",
    "bins = 100\n",
    "\n",
    "# Maximum order of the shown sensitivity indices \n",
    "max_order = 2\n",
    "\n",
    "# Verbose mode (True/False)\n",
    "verbose = True\n",
    "\n",
    "# Set a seed value (e.g. 9999) if you want to get\n",
    "# always the same results \n",
    "seed = None  # 9999\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piston function\n",
    "\n",
    "We will use as a first example a function modeling the circular motion of a piston within a cylinder with a chain of nonlinear functions:\n",
    "\n",
    "\\begin{equation}\n",
    "f(\\vec{x}) = 2 \\pi \\sqrt{\\frac{M}{k + S^2 \\frac{P_0 V_0}{T_0} \\frac{T_a}{V^2}}}\n",
    "\\end{equation}\n",
    "\n",
    "with:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{gathered}\n",
    "V = \\frac{S}{2k} \\left(\\sqrt{A^2 + 4k \\frac{P_0 V_0}{T_0} T_a} - A\\right) \\\\\n",
    "A = P_0 S + 19.62 M - \\frac{k V_0}{S}\n",
    "\\end{gathered}\n",
    "\\end{equation}\n",
    "\n",
    "More details about the function can be found at the [Virtual Library of Simulation Experiments](https://www.sfu.ca/~ssurjano/piston.html) from [Simon Fraser University](https://www.sfu.ca).\n",
    "\n",
    "The first step is to get the function object and the axis definitions from the library of test models included in TT recipes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get example function and axes definitions from 'ttrecipes.models'\n",
    "f_piston, axes_piston = tr.models.get_piston()\n",
    "pprint.pprint(axes_piston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the second parameter (_number of samples_) of every axes definitions is set to _'None'_. This means that the number of samples is not explicitly fixed and the default value will be used when calling to the function computing the sensitivity indices (__tr.sensitivity_analysis.var_metrics()__). The exact meaning of each one of the parameters is explained in the function documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tr.sensitivity_analysis.var_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's compute and show the actual indices. With __TT recipes__ this is as simple as calling the __tr.sensitivity_analysis.var_metrics()__ function with the function object and the axis definitions. In this example we set the parameter __print_results__ to __True__ to get the results tables printed.\n",
    "\n",
    "All the other parameters are optional and control different settings, as the default number of samples per axes when it is not specifically set for every axis, the target relative error of the approximation, and more specific settings for the TT cross approximation algorithm. Check the documentation of the function in the previous cell for a detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute sensitivity indices and print result tables\n",
    "print(\"+ Computing tensor approximations of variance-based sensitivity metrics...\")\n",
    "results = tr.sensitivity_analysis.var_metrics(\n",
    "    f_piston, axes_piston, default_bins=bins, verbose=verbose, eps=1e-5,\n",
    "    max_order=max_order, cross_kwargs=dict(),\n",
    "    print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default only indices up to second order are printed. If we are interested in higher order interactions, we can get them by changing the value of the *max_order* parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute sensitivity indices and print result tables\n",
    "print(\"+ Computing tensor approximations of variance-based sensitivity metrics...\")\n",
    "results = tr.sensitivity_analysis.var_metrics(\n",
    "    f_piston, axes_piston, default_bins=bins, verbose=verbose, eps=1e-5,\n",
    "    max_order=3, cross_kwargs=dict(),\n",
    "    print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobol __G__ function\n",
    "\n",
    "Let's try now a more challenging example using the __Sobol _G_ __ function, which is a well-known synthetic model that can be tune for generating low or high-order interactions depending on the vector of coefficients __a_i__. A much more detailed description of this function can be also found at the [Virtual Library of Simulation Experiments](https://www.sfu.ca/~ssurjano/gfunc.html).\n",
    "\n",
    "In this case, we will run the example with the same function parameters used in [2]:\n",
    "  - **dimensions**: 20\n",
    "  - **a_i**: 0 _[for i in range(n)]_\n",
    "\n",
    "Again, the first step is to get the function object and the axis definitions from models library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set example parameters\n",
    "dims = 20\n",
    "acoeff = 0\n",
    "\n",
    "# Get example function and axes definitions from 'ttrecipes.models'\n",
    "f_sobolg, axes_sobolg = tr.models.get_sobol_g(dims, a=acoeff, name_tmpl='X_{:0>2}')\n",
    "pprint.pprint(axes_sobolg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the function and axes have been defined for our specific case, we just need to pass them as parameters to the __tr.sensitivity_analysis.var_metrics()__  function to get all the sensitivity metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute sensitivity indices and print result tables\n",
    "print(\"+ Computing tensor approximations of variance-based sensitivity metrics...\")\n",
    "results = tr.sensitivity_analysis.var_metrics(\n",
    "    f_sobolg, axes_sobolg, default_bins=bins, verbose=verbose, eps=1e-10,\n",
    "    max_order=max_order, cross_kwargs=dict(kickrank=2),\n",
    "    print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated decay chain\n",
    "\n",
    "The third example simulates a radioactive decay chain that concatenates Poisson processes (it is a linear Jackson network) for 11 chemical species. Each species (except the last one) can decay into the next species in the chain.\n",
    "\n",
    "This model has 10 parameters, namely the decay rates $\\lambda_n$ of the 10 first species. The result of simulation $f_T(\\lambda_1, \\dots, \\lambda_{10})$ is the amount of stable material (last node in the chain) measured after a certain time span $T$. The function $f_T$ simulates the decay chain by discretizing the span $T$ into timesteps of one day. The $\\lambda_n$ (decay rates) represent the fraction of each material that decays every day. They are independent and uniformly distributed in the interval $[0.00063281, 0.00756736]$, which corresponds to half-lives from 3 years down to 3 months. The simulated time span for this example is set to 2 years ($T = 2$) as in [2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set example parameters\n",
    "span = 2\n",
    "products = 10\n",
    "\n",
    "f_decay, axes_decay = tr.models.get_decay_poisson(\n",
    "    d=products, span=span, hl_range=(3.0 * (1 / 12.0), 3.0),\n",
    "    time_step=1.0 / 365.0, name_tmpl='lambda_{:0>2}')\n",
    "pprint.pprint(axes_decay)\n",
    "\n",
    "print(\"+ Computing tensor approximations of variance-based sensitivity metrics...\")\n",
    "results = tr.sensitivity_analysis.var_metrics(\n",
    "    f_decay, axes_decay, default_bins=bins, verbose=verbose, eps=1e-4,\n",
    "    max_order=max_order, print_results=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire-spread model\n",
    "\n",
    "In the last example we use a function to model the rate of fire spread in the Mediterranean shrublands according to 10 variables that are fed into Rothermel's equations from [3]. We use the updated equations for the model from [4] since the authors kindly provided us the code of their function.\n",
    "\n",
    "[3] _A mathematical model for predicting fire spread in wildland fuels (Tech.\n",
    "Report)._ R. C. Rothermel. U.S. Department of Agriculture, Intermountain Forest and Range Experiment Station, 1972.\n",
    "\n",
    "[4] _Shapley effects for global sensitivity analysis: Theory\n",
    "and computation._ E. Song, B. L. Nelson, and J. Staum. SIAM/ASA Journal on Uncertainty Quantification, 4 (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_fire, axes_fire = tr.models.get_fire_spread(wind_factor=6.9)\n",
    "pprint.pprint(axes_fire)\n",
    "\n",
    "print(\"+ Computing tensor approximations of variance-based sensitivity metrics...\")\n",
    "results = tr.sensitivity_analysis.var_metrics(\n",
    "    f_fire, axes_fire, default_bins=bins, verbose=verbose, eps=1e-4,\n",
    "    max_order=max_order, cross_kwargs=dict(kickrank=4), print_results=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
